{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset split\n",
    "\n",
    "The goal of this notebook is to create train and validation sets and check their consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:41:32.882716Z",
     "start_time": "2020-10-06T00:41:32.873194Z"
    }
   },
   "outputs": [],
   "source": [
    "from thc.utils.env import check_repository_path\n",
    "\n",
    "\n",
    "REPOSITORY_DIR = check_repository_path()\n",
    "RAW_DATA_DIR = REPOSITORY_DIR.joinpath(\"data\", \"raw\")\n",
    "PROCESSED_DATA_DIR = REPOSITORY_DIR.joinpath(\"data\", \"processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already know from the [previous notebook](https://github.com/mrtovsky/thc/blob/main/notebooks/00-texts-integrity.ipynb) the whole dataset is significantly imbalanced so creation of the validation dataset should be done in the **stratified** fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:41:32.901465Z",
     "start_time": "2020-10-06T00:41:32.884397Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "\n",
    "TRAIN_TEXT_FILE = RAW_DATA_DIR.joinpath(\"training_set_clean_only_text.txt\")\n",
    "TRAIN_TAGS_FILE = RAW_DATA_DIR.joinpath(\"training_set_clean_only_tags.txt\")\n",
    "\n",
    "with codecs.open(str(TRAIN_TEXT_FILE), mode=\"r\", encoding=\"utf-8\") as file:\n",
    "    text = file.read().splitlines()\n",
    "with codecs.open(str(TRAIN_TAGS_FILE), mode=\"r\") as file:\n",
    "    tags = [int(tag) for tag in file]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split training dataset to create a holdout set for validation purposes. The corpus is small enough that cross-validation would be the correct approach to measure the model performance but repeating **DistilBERT** model fine-tuning would consume a lot of additional time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:41:33.541059Z",
     "start_time": "2020-10-06T00:41:32.903468Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "text_train, text_valid, tags_train, tags_valid = train_test_split(\n",
    "    text, tags,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    shuffle=True,\n",
    "    stratify=tags,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:41:33.613797Z",
     "start_time": "2020-10-06T00:41:33.542748Z"
    }
   },
   "outputs": [],
   "source": [
    "with codecs.open(str(PROCESSED_DATA_DIR.joinpath(\"train_text.txt\")), \"w\", \"utf-8\") as file:\n",
    "    for tweet in text_train:\n",
    "        file.write(f\"{tweet}\\n\")\n",
    "\n",
    "with codecs.open(str(PROCESSED_DATA_DIR.joinpath(\"valid_text.txt\")), \"w\", \"utf-8\") as file:\n",
    "    for tweet in text_valid:\n",
    "        file.write(f\"{tweet}\\n\")\n",
    "        \n",
    "with codecs.open(str(PROCESSED_DATA_DIR.joinpath(\"train_tags.txt\")), \"w\") as file:\n",
    "    for label in tags_train:\n",
    "        file.write(f\"{label}\\n\")\n",
    "\n",
    "with codecs.open(str(PROCESSED_DATA_DIR.joinpath(\"valid_tags.txt\")), \"w\") as file:\n",
    "    for label in tags_valid:\n",
    "        file.write(f\"{label}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy test data to **processed** folder as well and rename it for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-06T00:41:33.628902Z",
     "start_time": "2020-10-06T00:41:33.615340Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/usr/local/coding/thc-project/thc/data/processed/test_tags.txt')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "\n",
    "shutil.copy(\n",
    "    RAW_DATA_DIR.joinpath(\"test_set_only_text.txt\"),\n",
    "    PROCESSED_DATA_DIR.joinpath(\"test_text.txt\"),\n",
    ")\n",
    "shutil.copy(\n",
    "    RAW_DATA_DIR.joinpath(\"test_set_only_tags.txt\"),\n",
    "    PROCESSED_DATA_DIR.joinpath(\"test_tags.txt\"),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thc-venv",
   "language": "python",
   "name": "thc-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
